{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7f53cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.9.1\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub # Open repository and library for reusing trained models\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly()) # Dynamic graph just like Pytorch\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fe896b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1}\n",
      "{1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 13: 1, 10: 1, 11: 1, 12: 1, 9: 1}\n"
     ]
    }
   ],
   "source": [
    "# Bag of the words\n",
    "\n",
    "# words = input('Enter the word :').lower().split(' ')\n",
    "# print(words)\n",
    "vocab = dict()\n",
    "\n",
    "def bagofwords(words):\n",
    "    words = words.lower().split(' ')\n",
    "    i = 1\n",
    "    bag = dict()\n",
    "    for word in words:\n",
    "        if word not in vocab.keys():\n",
    "            vocab[word] = i\n",
    "            i+=1\n",
    "    for word in words:\n",
    "        bag[vocab[word]] = words.count(word)\n",
    "            \n",
    "    return bag\n",
    "\n",
    "print(bagofwords(\"I thought the movie was going to be bad but it was actually amazing\"))\n",
    "print(bagofwords(\"I thought the movie was going to be amazing but it was actually bad\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca6db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 5, 12, 13]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 13, 10, 11, 5, 12, 9]\n"
     ]
    }
   ],
   "source": [
    "# Integer Encoding - this keeps the order of the words intact \n",
    "vocab = dict()\n",
    "\n",
    "def integerencoding(words):\n",
    "    words = words.lower().split(' ')\n",
    "    i = 1\n",
    "    bag = []\n",
    "    for word in words:\n",
    "        if word not in vocab.keys():\n",
    "            vocab[word] = i\n",
    "            i+=1\n",
    "    for word in words:\n",
    "        bag.append(vocab[word])\n",
    "            \n",
    "    return bag\n",
    "\n",
    "print(integerencoding(\"I thought the movie was going to be bad but it was actually amazing\"))\n",
    "print(integerencoding(\"I thought the movie was going to be amazing but it was actually bad\"))\n",
    "\n",
    "# Word embedding - to keep the track of order aswell as labelling similar word as same\n",
    "# One hot encoding - Each word is represented by vector of size equal to dictionary and contains more sparse and doesn't take in account relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ca6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584 # This much words will be only kept which are encountered during training, more repeated words are given preference\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58604a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 194,\n",
       " 1153,\n",
       " 194,\n",
       " 8255,\n",
       " 78,\n",
       " 228,\n",
       " 5,\n",
       " 6,\n",
       " 1463,\n",
       " 4369,\n",
       " 5012,\n",
       " 134,\n",
       " 26,\n",
       " 4,\n",
       " 715,\n",
       " 8,\n",
       " 118,\n",
       " 1634,\n",
       " 14,\n",
       " 394,\n",
       " 20,\n",
       " 13,\n",
       " 119,\n",
       " 954,\n",
       " 189,\n",
       " 102,\n",
       " 5,\n",
       " 207,\n",
       " 110,\n",
       " 3103,\n",
       " 21,\n",
       " 14,\n",
       " 69,\n",
       " 188,\n",
       " 8,\n",
       " 30,\n",
       " 23,\n",
       " 7,\n",
       " 4,\n",
       " 249,\n",
       " 126,\n",
       " 93,\n",
       " 4,\n",
       " 114,\n",
       " 9,\n",
       " 2300,\n",
       " 1523,\n",
       " 5,\n",
       " 647,\n",
       " 4,\n",
       " 116,\n",
       " 9,\n",
       " 35,\n",
       " 8163,\n",
       " 4,\n",
       " 229,\n",
       " 9,\n",
       " 340,\n",
       " 1322,\n",
       " 4,\n",
       " 118,\n",
       " 9,\n",
       " 4,\n",
       " 130,\n",
       " 4901,\n",
       " 19,\n",
       " 4,\n",
       " 1002,\n",
       " 5,\n",
       " 89,\n",
       " 29,\n",
       " 952,\n",
       " 46,\n",
       " 37,\n",
       " 4,\n",
       " 455,\n",
       " 9,\n",
       " 45,\n",
       " 43,\n",
       " 38,\n",
       " 1543,\n",
       " 1905,\n",
       " 398,\n",
       " 4,\n",
       " 1649,\n",
       " 26,\n",
       " 6853,\n",
       " 5,\n",
       " 163,\n",
       " 11,\n",
       " 3215,\n",
       " 10156,\n",
       " 4,\n",
       " 1153,\n",
       " 9,\n",
       " 194,\n",
       " 775,\n",
       " 7,\n",
       " 8255,\n",
       " 11596,\n",
       " 349,\n",
       " 2637,\n",
       " 148,\n",
       " 605,\n",
       " 15358,\n",
       " 8003,\n",
       " 15,\n",
       " 123,\n",
       " 125,\n",
       " 68,\n",
       " 23141,\n",
       " 6853,\n",
       " 15,\n",
       " 349,\n",
       " 165,\n",
       " 4362,\n",
       " 98,\n",
       " 5,\n",
       " 4,\n",
       " 228,\n",
       " 9,\n",
       " 43,\n",
       " 36893,\n",
       " 1157,\n",
       " 15,\n",
       " 299,\n",
       " 120,\n",
       " 5,\n",
       " 120,\n",
       " 174,\n",
       " 11,\n",
       " 220,\n",
       " 175,\n",
       " 136,\n",
       " 50,\n",
       " 9,\n",
       " 4373,\n",
       " 228,\n",
       " 8255,\n",
       " 5,\n",
       " 25249,\n",
       " 656,\n",
       " 245,\n",
       " 2350,\n",
       " 5,\n",
       " 4,\n",
       " 9837,\n",
       " 131,\n",
       " 152,\n",
       " 491,\n",
       " 18,\n",
       " 46151,\n",
       " 32,\n",
       " 7464,\n",
       " 1212,\n",
       " 14,\n",
       " 9,\n",
       " 6,\n",
       " 371,\n",
       " 78,\n",
       " 22,\n",
       " 625,\n",
       " 64,\n",
       " 1382,\n",
       " 9,\n",
       " 8,\n",
       " 168,\n",
       " 145,\n",
       " 23,\n",
       " 4,\n",
       " 1690,\n",
       " 15,\n",
       " 16,\n",
       " 4,\n",
       " 1355,\n",
       " 5,\n",
       " 28,\n",
       " 6,\n",
       " 52,\n",
       " 154,\n",
       " 462,\n",
       " 33,\n",
       " 89,\n",
       " 78,\n",
       " 285,\n",
       " 16,\n",
       " 145,\n",
       " 95]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9f5ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(train_data, MAXLEN, padding = 'post') #Removes data from end and make all the tensors equals\n",
    "test_data = pad_sequences(test_data, MAXLEN, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c73bb361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32), # Embedding allows similar words with similar encoding input_lenght = 250, 32 is the single word will be represented by vector of size 32\n",
    "    tf.keras.layers.LSTM(32), # output of (batch_size, 32)\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21088cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecd208a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 35s 53ms/step - loss: 0.6404 - acc: 0.6285 - val_loss: 0.5027 - val_acc: 0.7924\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.4622 - acc: 0.8194 - val_loss: 0.4208 - val_acc: 0.8404\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 0.3769 - acc: 0.8679 - val_loss: 0.3953 - val_acc: 0.8534\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.3232 - acc: 0.8936 - val_loss: 0.4059 - val_acc: 0.8444\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.2938 - acc: 0.9028 - val_loss: 0.3719 - val_acc: 0.8640\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 0.2541 - acc: 0.9153 - val_loss: 0.3534 - val_acc: 0.8742\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 0.2509 - acc: 0.9201 - val_loss: 0.3471 - val_acc: 0.8766\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 0.2102 - acc: 0.9291 - val_loss: 0.3855 - val_acc: 0.8676\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.2328 - acc: 0.9237 - val_loss: 0.3644 - val_acc: 0.8628\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.2220 - acc: 0.9266 - val_loss: 0.4287 - val_acc: 0.8560\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8ec6bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 20ms/step - loss: 0.4947 - acc: 0.8303\n",
      "[0.49467000365257263, 0.8303200006484985]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28574e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
